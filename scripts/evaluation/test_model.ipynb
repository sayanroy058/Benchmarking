{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- ABSTRACT -->\n",
    "\n",
    "The goal of this script is to check how well the model performs on the test set. For this, we will look at the overall test set, as well as some specific cases, that we will visualize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import copy\n",
    "import json\n",
    "import joblib\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import geopandas as gpd\n",
    "\n",
    "import torch\n",
    "from torch_geometric.profile import count_parameters\n",
    "from torch.utils.data import Subset, DataLoader\n",
    "\n",
    "# Add the 'scripts' directory to Python Path\n",
    "scripts_path=os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "if scripts_path not in sys.path:\n",
    "    sys.path.append(scripts_path)\n",
    "\n",
    "import evaluation.help_functions as hf\n",
    "import evaluation.plot_functions as pf\n",
    "\n",
    "import gnn.gnn_io as gio\n",
    "from gnn.help_functions import compute_spearman_pearson\n",
    "from gnn.models.trans_conv import TransConv\n",
    "from training.help_functions import seed_worker, normalize_x_features_with_scaler, normalize_dataset\n",
    "from data_preprocessing.help_functions import highway_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the absolute path to the project root\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), '..', '..'))\n",
    "\n",
    "# Paths, adjust as needed\n",
    "run_path = os.path.join(project_root, \"data\", \"TR-C_Benchmarks\", \"tc_54x_part_4\")\n",
    "districts = gpd.read_file(os.path.join(project_root, \"data\", \"visualisation\", \"districts_paris.geojson\"))\n",
    "base_case_path = os.path.join(project_root, \"data\", \"links_and_stats\", \"pop_1pct_basecase_average_output_links.geojson\")\n",
    "result_path = 'results/'\n",
    "\n",
    "# GNN Parameters (Others are default values)\n",
    "in_channels = 5\n",
    "out_channels = 1\n",
    "use_dropout = False\n",
    "use_graph_norm = True\n",
    "use_residuals = True\n",
    "num_heads = 4\n",
    "hidden_channels = [32,64,128,256,256,256,256,256,256,256,256,256,256,256,256,256,256,256,256,256,256,256,256,256,256,256,256,256,256,256,256,256,256,256,256,256,256,256,256,256,256,256,256,256,256,256,256,256,256,256,256,128,64,32]\n",
    "\n",
    "links_base_case = gpd.read_file(base_case_path, crs=\"EPSG:4326\")\n",
    "data_created_during_training = os.path.join(run_path, 'data_created_during_training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################################\n",
    "### Load test data from the run itself! ###\n",
    "###########################################\n",
    "\n",
    "# Load scalers\n",
    "scaler_x = joblib.load(os.path.join(data_created_during_training, 'test_x_scaler.pkl'))\n",
    "scaler_pos = joblib.load(os.path.join(data_created_during_training, 'test_pos_scaler.pkl'))\n",
    "\n",
    "# Load the test dataset created during training\n",
    "test_set_dl = torch.load(os.path.join(data_created_during_training, 'test_dl.pt'))\n",
    "\n",
    "# Load the DataLoader parameters\n",
    "with open(os.path.join(data_created_during_training, 'test_loader_params.json'), 'r') as f:\n",
    "    test_set_dl_loader_params = json.load(f)\n",
    "    \n",
    "# Remove or correct collate_fn if it is incorrectly specified\n",
    "if 'collate_fn' in test_set_dl_loader_params and isinstance(test_set_dl_loader_params['collate_fn'], str):\n",
    "    del test_set_dl_loader_params['collate_fn']  # Remove it to use the default collate function\n",
    "    \n",
    "test_set_loader = torch.utils.data.DataLoader(test_set_dl, **test_set_dl_loader_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################\n",
    "### Load separate test data! ###\n",
    "################################\n",
    "\n",
    "dataset_path = os.path.join(project_root, \"data\", \"test_data\", \"pst_roads_in_inner_districts\")\n",
    "\n",
    "datalist = []\n",
    "batch_num = 1\n",
    "while True:\n",
    "    print(f\"Processing batch number: {batch_num}\")\n",
    "    batch_file = os.path.join(dataset_path, f'datalist_batch_{batch_num}.pt')\n",
    "    if not os.path.exists(batch_file):\n",
    "        break\n",
    "    batch_data = torch.load(batch_file, map_location='cpu')\n",
    "    if isinstance(batch_data, list):\n",
    "        datalist.extend(batch_data)\n",
    "    batch_num += 1\n",
    "print(f\"Loaded {len(datalist)} items into datalist\")\n",
    "\n",
    "dataset_length = len(datalist)\n",
    "test_indices = range(dataset_length)\n",
    "test_subset = Subset(datalist, test_indices)\n",
    "\n",
    "node_features = [\"VOL_BASE_CASE\",\n",
    "                 \"CAPACITY_BASE_CASE\",\n",
    "                 \"CAPACITY_REDUCTION\",\n",
    "                 \"FREESPEED\",\n",
    "                 \"LENGTH\"]\n",
    "\n",
    "### Use a new scaler! ###\n",
    "# test_set_normalized, scalers_test = normalize_dataset(dataset_input=test_subset, node_features=node_features)\n",
    "# test_set_loader = DataLoader(dataset=test_set_normalized, batch_size=8,\n",
    "#                              shuffle=True, num_workers=4, collate_fn=gio.collate_fn, worker_init_fn=seed_worker)\n",
    "# scaler_x = scalers_test['x_scaler']\n",
    "# scaler_pos = scalers_test['pos_scaler']\n",
    "##########################\n",
    "\n",
    "##### Load scalers from the run for consistency! #####\n",
    "scaler_x = joblib.load(os.path.join(data_created_during_training, 'test_x_scaler.pkl'))\n",
    "data_list = [copy.deepcopy(test_subset.dataset[idx]) for idx in test_subset.indices]\n",
    "test_set_normalized = normalize_x_features_with_scaler(data_list, node_features, scaler_x)\n",
    "test_set_loader = DataLoader(dataset=test_set_normalized, batch_size=8,\n",
    "                             shuffle=True, num_workers=4, collate_fn=gio.collate_fn, worker_init_fn=seed_worker)\n",
    "######################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TransConv(use_dropout=use_dropout, use_graph_norm=use_graph_norm, use_residuals=use_residuals,\n",
    "                  in_channels=in_channels, out_channels=out_channels, num_heads=num_heads,\n",
    "                  hidden_channels=hidden_channels)\n",
    "\n",
    "print(f\"Trainable model parameters: {round(count_parameters(model) / 1e6, 2)} M\")\n",
    "\n",
    "# Load the model state dictionary\n",
    "model_path = os.path.join(run_path, 'trained_model/model.pth')\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "\n",
    "loss_fct = torch.nn.MSELoss().to(dtype=torch.float32).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic Test\n",
    "\n",
    "test_loss, r_squared, actual_vals, predictions, baseline_loss = hf.validate_model_on_test_set(model, test_set_loader.dataset, loss_fct, device)\n",
    "spearman, pearson = compute_spearman_pearson(predictions, actual_vals)\n",
    "\n",
    "print(f\"Test Loss: {test_loss}\")\n",
    "print(f\"R-squared: {r_squared}\")\n",
    "print(f\"Spearman Correlation: {spearman}\")\n",
    "print(f\"Pearson Correlation: {pearson}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next, we will look at single elements of the test set and visualize the performance of the model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 2 # index from the test set, pick a particular sample\n",
    "\n",
    "fixed_norm_max = 50\n",
    "    \n",
    "my_test_data = test_set_loader.dataset[i]\n",
    "my_test_x = test_set_loader.dataset[i].x\n",
    "my_test_x = my_test_x.to('cpu')\n",
    "\n",
    "test_loss_my_test_data, r_squared_my_test_data, actual_vals_my_test_data, predictions_my_test_data, baseline_loss_my_test_data = hf.validate_model_on_test_set(model, my_test_data, loss_fct, device)\n",
    "print(f\"Sample {i}\")\n",
    "print(f\"Test Loss: {test_loss_my_test_data}\")\n",
    "print(f\"R-squared: {r_squared_my_test_data}\")\n",
    "print(f\"Baseline Loss: {baseline_loss_my_test_data}\")\n",
    "\n",
    "inversed_x = scaler_x.inverse_transform(my_test_x)\n",
    "\n",
    "gdf_with_og_values = hf.data_to_geodataframe_with_og_values(data=my_test_data, original_gdf=links_base_case, predicted_values=predictions_my_test_data, inversed_x=inversed_x)\n",
    "gdf_with_og_values['capacity_reduction_rounded'] = gdf_with_og_values['capacity_reduction'].round(decimals=3)\n",
    "gdf_with_og_values['highway'] = gdf_with_og_values['highway'].map(highway_mapping)\n",
    "\n",
    "# gdf_with_og_values['district'] = gdf_with_og_values.apply(lambda row: districts[districts.contains(row.geometry)].iloc[0]['c_ar'] if not districts[districts.contains(row.geometry)].empty else 'Unknown', axis=1)\n",
    "# gdf_with_og_values = gpd.sjoin(gdf_with_og_values, districts, how='left', op='intersects')\n",
    "\n",
    "print(f\"\\nPredicted:\")\n",
    "pf.plot_combined_output(gdf_input=gdf_with_og_values, column_to_plot=\"vol_car_change_predicted\", is_predicted=True,\n",
    "                        save_it=False, number_to_plot=i, result_path=result_path,\n",
    "                        use_fixed_norm=True, fixed_norm_max=fixed_norm_max, known_districts=False, districts_of_interest=None,\n",
    "                        plot_contour_lines=True, plot_policy_roads=False, with_legend=True)\n",
    "\n",
    "print(f\"Actual:\")\n",
    "pf.plot_combined_output(gdf_input=gdf_with_og_values, column_to_plot=\"vol_car_change_actual\", is_predicted=False,\n",
    "                        save_it=False, number_to_plot=i, result_path=result_path,\n",
    "                        use_fixed_norm=True, fixed_norm_max=fixed_norm_max, known_districts=False, districts_of_interest=None,\n",
    "                        plot_contour_lines=True, plot_policy_roads=False, with_legend=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot results across the entire test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create gdfs for the entire test set\n",
    "gdfs = []\n",
    "\n",
    "for i in tqdm(range(len(test_set_loader.dataset))):\n",
    "    my_test_data = test_set_loader.dataset[i]\n",
    "    my_test_x = test_set_loader.dataset[i].x\n",
    "    my_test_x = my_test_x.to('cpu')\n",
    "    \n",
    "    test_loss_my_test_data, r_squared_my_test_data, actual_vals_my_test_data, predictions_my_test_data, baseline_loss_my_test_data = hf.validate_model_on_test_set(model, my_test_data, loss_fct, device)\n",
    "    inversed_x = scaler_x.inverse_transform(my_test_x)\n",
    "    \n",
    "    gdf = hf.data_to_geodataframe_with_og_values(data=my_test_data, original_gdf=links_base_case, predicted_values=predictions_my_test_data, inversed_x=inversed_x)\n",
    "    \n",
    "    # gdf = gpd.sjoin(gdf, districts, how='left', op='intersects')\n",
    "    # gdf = gdf.rename(columns={\"c_ar\": \"district\"})\n",
    "    \n",
    "    gdf['capacity_reduction_rounded'] = gdf['capacity_reduction'].round(decimals=3)\n",
    "    gdf['highway'] = gdf['highway'].map(highway_mapping)\n",
    "    \n",
    "    gdfs.append(gdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discrete plot for prediction error\n",
    "# Absolute differences in number of vehicles\n",
    "discrete_thresholds=(2.5,5,7.5)\n",
    "\n",
    "result_gdf = pf.plot_average_prediction_differences(\n",
    "    gdf_inputs=gdfs,\n",
    "    scale_type=\"discrete\",\n",
    "    discrete_thresholds=discrete_thresholds,\n",
    "    save_it=True,\n",
    "    use_fixed_norm=True,\n",
    "    fixed_norm_max=100,\n",
    "    use_absolute_value_of_difference=True,\n",
    "    use_percentage=False,\n",
    "    disagreement_threshold=None,\n",
    "    result_path=result_path,\n",
    "    loss_fct=\"l1\",\n",
    "    cmap = 'Spectral_r'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Continuous plot for prediction error, relative difference.\n",
    "discrete_thresholds = (10, 25, 50)\n",
    "\n",
    "result_gdf = pf.plot_average_prediction_differences(\n",
    "    gdf_inputs=gdfs,\n",
    "    scale_type=\"discrete\",\n",
    "    discrete_thresholds=discrete_thresholds,\n",
    "    save_it=True,\n",
    "    use_fixed_norm=True,\n",
    "    fixed_norm_max=100,\n",
    "    use_absolute_value_of_difference=True,\n",
    "    use_percentage=True,\n",
    "    disagreement_threshold=None,\n",
    "    result_path=result_path,\n",
    "    loss_fct=\"l1\",\n",
    "    cmap = 'Spectral_r'\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chenhao-gnn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
