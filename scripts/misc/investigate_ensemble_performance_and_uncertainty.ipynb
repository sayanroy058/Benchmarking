{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- ABSTRACT -->\n",
    "\n",
    "With this script, we evaluate the ensembles and check how well they perform. The result is a plot of the uncertainty of the model's predictions. However, it seems that the uncertainty is not very high."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import joblib\n",
    "\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from scipy import stats\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams[\"font.family\"] = \"Times New Roman\"\n",
    "\n",
    "import torch\n",
    "\n",
    "# Add the 'scripts' directory to Python Path\n",
    "scripts_path=os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "if scripts_path not in sys.path:\n",
    "    sys.path.append(scripts_path)\n",
    "\n",
    "import evaluation.help_functions as hf\n",
    "import evaluation.plot_functions as pf\n",
    "\n",
    "from gnn.help_functions import mc_dropout_predict\n",
    "from gnn.models.point_net_transf_gat import PointNetTransfGAT\n",
    "from data_preprocessing.help_functions import highway_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the absolute path to the project root\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), '..', '..'))\n",
    "\n",
    "# Paths\n",
    "runs_path = os.path.join(project_root, \"data\", \"runs_01_2025\")\n",
    "ensembles = [\"ensemble_1\",\n",
    "             \"ensemble_2\",\n",
    "             \"ensemble_3\",\n",
    "             \"ensemble_4_lrz\",\n",
    "             \"ensemble_5\"]\n",
    "\n",
    "# Dropout for Ensembles\n",
    "use_dropout = [False,\n",
    "               False,\n",
    "               False,\n",
    "               True,\n",
    "               True]\n",
    "\n",
    "districts = gpd.read_file(os.path.join(project_root, \"data\", \"visualisation\", \"districts_paris.geojson\"))\n",
    "base_case_path = os.path.join(project_root, \"data\", \"links_and_stats\", \"pop_1pct_basecase_average_output_links.geojson\")\n",
    "links_base_case = gpd.read_file(base_case_path, crs=\"EPSG:4326\")\n",
    "\n",
    "# GNN Parameters\n",
    "point_net_conv_layer_structure_local_mlp=\"256\"\n",
    "point_net_conv_layer_structure_global_mlp = \"512\"\n",
    "gat_conv_layer_structure = \"128,256,512\"\n",
    "predict_mode_stats = False\n",
    "in_channels = 5\n",
    "out_channels = 1\n",
    "\n",
    "point_net_conv_layer_structure_local_mlp = [int(x) for x in point_net_conv_layer_structure_local_mlp.split(',')]\n",
    "point_net_conv_layer_structure_global_mlp = [int(x) for x in point_net_conv_layer_structure_global_mlp.split(',')]\n",
    "gat_conv_layer_structure = [int(x) for x in gat_conv_layer_structure.split(',')]\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "loss_fct = torch.nn.MSELoss().to(dtype=torch.float32).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load test set and scalers\n",
    "# Same for each ensemble with seed=42\n",
    "\n",
    "ensemble_path = os.path.join(runs_path, ensembles[0])\n",
    "data_created_during_training = os.path.join(ensemble_path, 'data_created_during_training/')\n",
    "\n",
    "# Load scalers\n",
    "scaler_x = joblib.load(data_created_during_training + 'test_x_scaler.pkl')\n",
    "scaler_pos = joblib.load(data_created_during_training + 'test_pos_scaler.pkl')\n",
    "\n",
    "# Load the test dataset created during training\n",
    "test_set_dl = torch.load(data_created_during_training + 'test_dl.pt')\n",
    "\n",
    "# Load the DataLoader parameters\n",
    "with open(data_created_during_training + 'test_loader_params.json', 'r') as f:\n",
    "    test_set_dl_loader_params = json.load(f)\n",
    "    \n",
    "# Remove or correct collate_fn if it is incorrectly specified\n",
    "if 'collate_fn' in test_set_dl_loader_params and isinstance(test_set_dl_loader_params['collate_fn'], str):\n",
    "    del test_set_dl_loader_params['collate_fn']  # Remove it to use the default collate function\n",
    "    \n",
    "test_set_loader = torch.utils.data.DataLoader(test_set_dl, **test_set_dl_loader_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_ensemble(ensemble, model_path, use_dropout):\n",
    "\n",
    "    model = PointNetTransfGAT(in_channels=in_channels, out_channels=out_channels,\n",
    "            point_net_conv_layer_structure_local_mlp=point_net_conv_layer_structure_local_mlp, \n",
    "            point_net_conv_layer_structure_global_mlp = point_net_conv_layer_structure_global_mlp,\n",
    "            gat_conv_layer_structure=gat_conv_layer_structure,\n",
    "            use_dropout=use_dropout,\n",
    "            predict_mode_stats=predict_mode_stats)\n",
    "    \n",
    "    model = model.to(device)\n",
    "    model.load_state_dict(torch.load(model_path), strict=False)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Individual Ensembles Evaluation\n",
    "\n",
    "for i, ensemble in enumerate(ensembles):\n",
    "\n",
    "    model_path = os.path.join(runs_path, ensemble, 'trained_model/model.pth')\n",
    "    model = load_ensemble(ensemble, model_path, use_dropout[i])\n",
    "    \n",
    "    test_loss, r_squared, actual_vals, predictions, baseline_loss = hf.validate_model_on_test_set(model, test_set_loader.dataset, loss_fct, device)\n",
    "\n",
    "    print(f\"\\n{ensemble}:\")\n",
    "    print(f\"Test Loss: {test_loss}\")\n",
    "    print(f\"R-squared: {r_squared}\")\n",
    "    print(f\"Baseline Loss: {baseline_loss}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "print(f\"Results for sample {i}\\n\")\n",
    "\n",
    "test_data = test_set_loader.dataset[i]\n",
    "test_x = test_set_loader.dataset[i].x\n",
    "test_x = test_x.to('cpu')\n",
    "\n",
    "for i, ensemble in enumerate(ensembles):\n",
    "\n",
    "    print(f\"Results for {ensemble}:\")\n",
    "\n",
    "    model_path = os.path.join(runs_path,ensemble,'trained_model/model.pth')\n",
    "    model = load_ensemble(ensemble, model_path, use_dropout[i])\n",
    "\n",
    "    test_loss, r_squared, actual_vals, predictions, baseline_loss = hf.validate_model_on_test_set(model, test_data, loss_fct, device)\n",
    "\n",
    "    print(f\"Test Loss: {test_loss}\")\n",
    "    print(f\"R-squared: {r_squared}\")\n",
    "    print(f\"Baseline Loss: {baseline_loss}\")\n",
    "\n",
    "    inversed_x = scaler_x.inverse_transform(test_x)\n",
    "\n",
    "    gdf_with_og_values = hf.data_to_geodataframe_with_og_values(data=test_data, original_gdf=links_base_case, predicted_values=predictions, inversed_x=inversed_x, use_all_features=False)\n",
    "    gdf_with_og_values['capacity_reduction_rounded'] = gdf_with_og_values['capacity_reduction'].round(decimals=3)\n",
    "    gdf_with_og_values['highway'] = gdf_with_og_values['highway'].map(highway_mapping)\n",
    "\n",
    "    # print(\"\\nPredicted values:\")\n",
    "    # pf.plot_combined_output(gdf_input=gdf_with_og_values, column_to_plot=\"vol_car_change_predicted\", \n",
    "    #                         save_it=False, number_to_plot=i, zone_to_plot = \"this zone\", is_predicted=True, alpha=0, \n",
    "    #                         use_fixed_norm=False, fixed_norm_max = fixed_norm_max,\n",
    "    #                         known_districts = False, buffer = 0.0005, \n",
    "    #                         plot_policy_roads = True, \n",
    "    #                         plot_contour_lines = True, \n",
    "    #                         districts_of_interest=None)\n",
    "\n",
    "    # print(\"Actual values:\")\n",
    "    # pf.plot_combined_output(gdf_input=gdf_with_og_values, column_to_plot=\"vol_car_change_actual\", save_it=False, \n",
    "    #                         number_to_plot=i, zone_to_plot = \"this zone\",is_predicted=False,alpha=10,\n",
    "    #                         use_fixed_norm=False, fixed_norm_max = fixed_norm_max,\n",
    "    #                         known_districts = False, buffer = 0.0005, \n",
    "    #                         plot_policy_roads = True, \n",
    "    #                         plot_contour_lines = True, \n",
    "    #                         districts_of_interest=None)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensemble_predict(model, data, device):\n",
    "    \n",
    "    predictions = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, ensemble in enumerate(ensembles):\n",
    "            \n",
    "            model_path = os.path.join(runs_path, ensemble, 'trained_model/model.pth')\n",
    "            model = load_ensemble(ensemble, model_path, use_dropout[i])\n",
    "            model.eval()\n",
    "\n",
    "            pred = model(data.to(device))\n",
    "            if isinstance(pred, tuple):  # If multiple outputs (e.g., mode_stats)\n",
    "                pred = pred[0]\n",
    "            predictions.append(pred.cpu().numpy())  # Collect predictions\n",
    "\n",
    "    # Stack predictions and calculate statistics\n",
    "    predictions = np.stack(predictions, axis=0)  # Shape: (num_ensembles, num_predictions)\n",
    "    mean_prediction = predictions.mean(axis=0)  # Mean prediction\n",
    "    uncertainty = predictions.std(axis=0)       # Uncertainty (standard deviation)\n",
    "\n",
    "    return mean_prediction, uncertainty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensemble uncertainty on single sample\n",
    "\n",
    "i = 32\n",
    "print(f\"Ensemble uncertainty for sample {i}:\")\n",
    "\n",
    "test_data = test_set_loader.dataset[i]\n",
    "test_x = test_set_loader.dataset[i].x\n",
    "test_x = test_x.to('cpu')\n",
    "\n",
    "inversed_x = scaler_x.inverse_transform(test_x)\n",
    "mean_predictions, uncertainties = ensemble_predict(model, test_data, device=device)\n",
    "\n",
    "gdf_with_og_values = hf.data_to_geodataframe_with_og_values(data=test_data, original_gdf=links_base_case, predicted_values=mean_predictions, inversed_x=inversed_x, use_all_features=False)\n",
    "gdf_with_og_values['capacity_reduction_rounded'] = gdf_with_og_values['capacity_reduction'].round(decimals=3)\n",
    "gdf_with_og_values['highway'] = gdf_with_og_values['highway'].map(highway_mapping)\n",
    "gdf_with_og_values['ensemble_uncertainty'] = uncertainties\n",
    "\n",
    "pf.plot_combined_output(gdf_input=gdf_with_og_values, column_to_plot=\"ensemble_uncertainty\", plot_contour_lines=False,\n",
    "                        save_it=False, number_to_plot=i, zone_to_plot = \"this zone\", is_predicted=True, use_fixed_norm=False,\n",
    "                        known_districts = False, buffer = 0.0005, districts_of_interest=None, cmap='Reds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensemble uncertainty on entire test set\n",
    "\n",
    "mean_uncertainties = []\n",
    "\n",
    "for i in tqdm.tqdm(range(len(test_set_loader.dataset))):\n",
    "    \n",
    "    test_data = test_set_loader.dataset[i]\n",
    "    test_x = test_set_loader.dataset[i].x\n",
    "    test_x = test_x.to('cpu')\n",
    "\n",
    "    mean_predictions, uncertainties = ensemble_predict(model, test_data, device=device)\n",
    "    mean_uncertainties.append(uncertainties)\n",
    "\n",
    "mean_uncertainties = np.array(mean_uncertainties).mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some stats to pick discrete bins\n",
    "\n",
    "flat_uc = np.sort(mean_uncertainties.flatten())\n",
    "\n",
    "percentile_1 = np.percentile(flat_uc, 25)\n",
    "percentile_2 = np.percentile(flat_uc, 75)\n",
    "\n",
    "print(f\"1st Percentile: {percentile_1}\")\n",
    "print(f\"2nd Percentile: {percentile_2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On the last sample, but does not matter\n",
    "inversed_x = scaler_x.inverse_transform(test_x)\n",
    "gdf_with_og_values = hf.data_to_geodataframe_with_og_values(data=test_data, original_gdf=links_base_case, predicted_values=mean_predictions, inversed_x=inversed_x, use_all_features=False)\n",
    "gdf_with_og_values['capacity_reduction_rounded'] = gdf_with_og_values['capacity_reduction'].round(decimals=3)\n",
    "gdf_with_og_values['highway'] = gdf_with_og_values['highway'].map(highway_mapping)\n",
    "gdf_with_og_values['ensemble_uncertainty'] = mean_uncertainties\n",
    "\n",
    "dicrete_thresholds = [1,2]\n",
    "\n",
    "pf.plot_combined_output(gdf_input=gdf_with_og_values, column_to_plot=\"ensemble_uncertainty\", plot_contour_lines=False,\n",
    "                        save_it=False, number_to_plot=i+1, zone_to_plot = \"this zone\", is_predicted=True, use_fixed_norm=False,\n",
    "                        known_districts = False, buffer = 0.0005, districts_of_interest=None, scale_type='discrete', discrete_thresholds=dicrete_thresholds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bias Variance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ensemble_predictions_on_test_set(test_set_loader, device):\n",
    "    \"\"\"Get raw predictions from all ensemble members\"\"\"\n",
    "    all_predictions = []\n",
    "    \n",
    "    for i, ensemble in (enumerate(tqdm(ensembles))):\n",
    "        \n",
    "        model_path = os.path.join(runs_path, ensemble, 'trained_model/model.pth')\n",
    "        model = load_ensemble(ensemble, model_path, use_dropout[i])\n",
    "\n",
    "        test_loss, r_squared, actual_vals, predictions, baseline_loss = hf.validate_model_on_test_set(model, test_set_loader.dataset, loss_fct, device)\n",
    "        all_predictions.append(predictions.view(predictions.shape[0]//31635, 31635).cpu().numpy())\n",
    "    \n",
    "    return np.array(all_predictions), np.array(actual_vals.view(actual_vals.shape[0]//31635, 31635).cpu().numpy())\n",
    "\n",
    "all_predictions, all_actuals = get_ensemble_predictions_on_test_set(test_set_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_bias_variance(actual_values, ensemble_predictions):\n",
    "    \"\"\"\n",
    "    Compute bias and variance from ensemble predictions\n",
    "    \n",
    "    Parameters:\n",
    "    - actual_values: numpy array of true values\n",
    "    - ensemble_predictions: numpy array of shape (n_ensembles, n_samples)\n",
    "    \n",
    "    Returns:\n",
    "    - bias: average bias (squared difference between mean prediction and true values)\n",
    "    - variance: average variance of predictions\n",
    "    \"\"\"\n",
    "    mean_predictions = np.mean(ensemble_predictions, axis=0)\n",
    "    \n",
    "    # Compute bias (squared difference between mean prediction and true value)\n",
    "    bias = np.mean((mean_predictions - actual_values) ** 2)\n",
    "    \n",
    "    # Compute variance (average variance of predictions across ensemble members)\n",
    "    variance = np.mean(np.var(ensemble_predictions, axis=0))\n",
    "    \n",
    "    return bias, variance\n",
    "\n",
    "# Overall bias-variance\n",
    "overall_bias, overall_variance = compute_bias_variance(all_actuals, all_predictions)\n",
    "print(f\"\\nOverall Metrics:\")\n",
    "print(f\"Bias: {overall_bias:.4f}\")\n",
    "print(f\"Variance: {overall_variance:.4f}\")\n",
    "print(f\"Total Error (Bias + Variance): {overall_bias + overall_variance:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_highway_mapping = {\n",
    "    'trunk': 0,\n",
    "    'primary': 1,\n",
    "    'secondary': 2,\n",
    "    'tertiary': 3,\n",
    "    'residential': 4, 'living_street': 5,\n",
    "    'pedestrian': 6, 'service': 7,\n",
    "    'construction': 8, 'unclassified': 9,\n",
    "    'all_types': 'all types'\n",
    "}\n",
    "\n",
    "highway_descriptions = {\n",
    "    'trunk': 'Trunk Roads',\n",
    "    'primary': 'Primary Roads',\n",
    "    'secondary': 'Secondary Roads',\n",
    "    'tertiary': 'Tertiary Roads',\n",
    "    'living_street': 'Living Streets',\n",
    "    'residential': 'Residential Streets'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Bias-Variance by Road Type:\")\n",
    "for highway_type, code in simple_highway_mapping.items():\n",
    "    if highway_type == 'all_types':\n",
    "        continue\n",
    "    \n",
    "    # Get mask for this road type\n",
    "    road_mask = gdf_with_og_values['highway'] == code\n",
    "    if not road_mask.any():\n",
    "        continue\n",
    "    \n",
    "    # Get predictions for this road type\n",
    "    road_predictions = all_predictions[:, :, road_mask]  # Shape: (5, 831, n_roads_of_type)\n",
    "    road_predictions = road_predictions.reshape(5, -1)  # Shape: (5, 831 * n_roads_of_type)\n",
    "    \n",
    "    # Handle actuals - first reshape to remove last dimension of 1, then apply mask\n",
    "    actuals_reshaped = all_actuals.reshape(831, -1)  # Shape: (831, 31635)\n",
    "    road_actuals = actuals_reshaped[:, road_mask].reshape(-1)  # Shape: (831 * n_roads_of_type)\n",
    "    \n",
    "    # Compute metrics\n",
    "    road_bias, road_variance = compute_bias_variance(road_actuals, road_predictions)\n",
    "    print(f\"\\n{highway_type}:\")\n",
    "    print(f\"Bias: {road_bias:.4f}\")\n",
    "    print(f\"Variance: {road_variance:.4f}\")\n",
    "    print(f\"Total Error: {road_bias + road_variance:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Road types we're interested in\n",
    "road_types_of_interest = ['primary', 'secondary', 'tertiary']\n",
    "\n",
    "# Create gdf_with_og_values, just for having the dataframe.\n",
    "i = 0\n",
    "test_data = test_set_loader.dataset[i]\n",
    "test_x = test_set_loader.dataset[i].x\n",
    "test_x = test_x.to('cpu')\n",
    "links_base_case = gpd.read_file(base_case_path, crs=\"EPSG:4326\")\n",
    "\n",
    "for i, ensemble in enumerate(ensembles):\n",
    "    model_path = os.path.join(runs_path,ensemble,'trained_model/model.pth')\n",
    "    model = load_ensemble(ensemble, model_path, use_dropout[i])\n",
    "    inversed_x = scaler_x.inverse_transform(test_x)\n",
    "    gdf_with_og_values = hf.data_to_geodataframe_with_og_values(data=test_data, original_gdf=links_base_case, predicted_values=predictions, inversed_x=inversed_x, use_all_features=False)\n",
    "    gdf_with_og_values['capacity_reduction_rounded'] = gdf_with_og_values['capacity_reduction'].round(decimals=3)\n",
    "    gdf_with_og_values['highway'] = gdf_with_og_values['highway'].map(highway_mapping)\n",
    "    break\n",
    "\n",
    "print(\"\\nBias-Variance by Road Type and Capacity Reduction:\")\n",
    "for highway_type in road_types_of_interest:\n",
    "    description = highway_descriptions[highway_type]\n",
    "    \n",
    "    # Base mask for road type\n",
    "    road_type_mask = gdf_with_og_values['highway'] == highway_mapping[highway_type]\n",
    "    \n",
    "    # Create masks for with and without capacity reduction\n",
    "    with_reduction_mask = road_type_mask & (gdf_with_og_values['capacity_reduction_rounded'] < 0)\n",
    "    without_reduction_mask = road_type_mask & (gdf_with_og_values['capacity_reduction_rounded'] == 0)\n",
    "    \n",
    "    for mask, condition in [(with_reduction_mask, \"with capacity reduction\"), \n",
    "                           (without_reduction_mask, \"without capacity reduction\")]:\n",
    "        if not mask.any():\n",
    "            print(f\"\\n{description} {condition}: No roads found\")\n",
    "            continue\n",
    "            \n",
    "        # Get predictions for this combination\n",
    "        road_predictions = all_predictions[:, :, mask]\n",
    "        road_predictions = road_predictions.reshape(5, -1)\n",
    "        \n",
    "        # Handle actuals\n",
    "        actuals_reshaped = all_actuals.reshape(831, -1)\n",
    "        road_actuals = actuals_reshaped[:, mask].reshape(-1)\n",
    "        \n",
    "        # Compute metrics\n",
    "        road_bias, road_variance = compute_bias_variance(road_actuals, road_predictions)\n",
    "        print(f\"\\n{description} {condition}:\")\n",
    "        print(f\"Number of road segments: {mask.sum()}\")\n",
    "        print(f\"Bias: {road_bias:.4f}\")\n",
    "        print(f\"Variance: {road_variance:.4f}\")\n",
    "        print(f\"Total Error: {road_bias + road_variance:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Across all ensembles ###\n",
    "\n",
    "# Road types we're interested in\n",
    "road_types_of_interest = ['primary', 'secondary', 'tertiary']\n",
    "\n",
    "# Create gdf_with_og_values with averaged predictions across all ensembles and all test samples\n",
    "test_x = test_set_loader.dataset[0].x  # Just to get inversed_x for the geodataframe\n",
    "test_x = test_x.to('cpu')\n",
    "links_base_case = gpd.read_file(base_case_path, crs=\"EPSG:4326\")\n",
    "inversed_x = scaler_x.inverse_transform(test_x)\n",
    "\n",
    "# Average predictions across all test samples and ensembles\n",
    "mean_predictions = np.mean(all_predictions, axis=(0, 1))  # Average over samples (831) and ensembles (5)\n",
    "\n",
    "# Create geodataframe with mean predictions\n",
    "gdf_with_og_values = hf.data_to_geodataframe_with_og_values(data=test_set_loader.dataset[0], \n",
    "                                                           original_gdf=links_base_case, \n",
    "                                                           predicted_values=mean_predictions, \n",
    "                                                           inversed_x=inversed_x, \n",
    "                                                           use_all_features=False)\n",
    "gdf_with_og_values['capacity_reduction_rounded'] = gdf_with_og_values['capacity_reduction'].round(decimals=3)\n",
    "gdf_with_og_values['highway'] = gdf_with_og_values['highway'].map(highway_mapping)\n",
    "\n",
    "print(\"\\nBias-Variance by Road Type and Capacity Reduction:\")\n",
    "for highway_type in road_types_of_interest:\n",
    "    description = highway_descriptions[highway_type]\n",
    "    \n",
    "    # Base mask for road type\n",
    "    road_type_mask = gdf_with_og_values['highway'] == highway_mapping[highway_type]\n",
    "    \n",
    "    # Create masks for with and without capacity reduction\n",
    "    with_reduction_mask = road_type_mask & (gdf_with_og_values['capacity_reduction_rounded'] < 0)\n",
    "    without_reduction_mask = road_type_mask & (gdf_with_og_values['capacity_reduction_rounded'] == 0)\n",
    "    \n",
    "    for mask, condition in [(with_reduction_mask, \"with capacity reduction\"), \n",
    "                           (without_reduction_mask, \"without capacity reduction\")]:\n",
    "        if not mask.any():\n",
    "            print(f\"\\n{description} {condition}: No roads found\")\n",
    "            continue\n",
    "            \n",
    "        # Get predictions for this combination\n",
    "        road_predictions = all_predictions[:, :, mask]\n",
    "        road_predictions = road_predictions.reshape(5, -1)\n",
    "        \n",
    "        # Handle actuals\n",
    "        actuals_reshaped = all_actuals.reshape(831, -1)\n",
    "        road_actuals = actuals_reshaped[:, mask].reshape(-1)\n",
    "        \n",
    "        # Compute metrics\n",
    "        road_bias, road_variance = compute_bias_variance(road_actuals, road_predictions)\n",
    "        print(f\"\\n{description} {condition}:\")\n",
    "        print(f\"Number of road segments: {mask.sum()}\")\n",
    "        print(f\"Bias: {road_bias:.4f}\")\n",
    "        print(f\"Variance: {road_variance:.4f}\")\n",
    "        print(f\"Total Error: {road_bias + road_variance:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define road types\n",
    "basic_road_types = ['trunk', 'primary', 'secondary', 'tertiary', 'living_street', 'residential']\n",
    "pst_road_types = ['primary', 'secondary', 'tertiary']\n",
    "\n",
    "# Collect results in a structured format\n",
    "results = []\n",
    "\n",
    "# First, add all basic road types (without distinguishing capacity reduction)\n",
    "for highway_type in basic_road_types:\n",
    "    description = highway_descriptions[highway_type]\n",
    "    \n",
    "    # Base mask for road type\n",
    "    road_type_mask = gdf_with_og_values['highway'] == highway_mapping[highway_type]\n",
    "    if not road_type_mask.any():\n",
    "        continue\n",
    "        \n",
    "    road_predictions = all_predictions[:, :, road_type_mask]\n",
    "    road_predictions = road_predictions.reshape(5, -1)\n",
    "    actuals_reshaped = all_actuals.reshape(831, -1)\n",
    "    road_actuals = actuals_reshaped[:, road_type_mask].reshape(-1)\n",
    "    \n",
    "    road_bias, road_variance = compute_bias_variance(road_actuals, road_predictions)\n",
    "    \n",
    "    results.append({\n",
    "        'Road Category': description,\n",
    "        'Bias': road_bias,\n",
    "        'Surrogate Model Variance': road_variance,\n",
    "        'Total Error': road_bias + road_variance\n",
    "    })\n",
    "\n",
    "# Now add PST roads with and without capacity reduction\n",
    "pst_mask = np.zeros(len(gdf_with_og_values), dtype=bool)\n",
    "for highway_type in pst_road_types:\n",
    "    pst_mask |= (gdf_with_og_values['highway'] == highway_mapping[highway_type])\n",
    "\n",
    "# With capacity reduction\n",
    "with_reduction_mask = pst_mask & (gdf_with_og_values['capacity_reduction_rounded'] < 0)\n",
    "road_predictions = all_predictions[:, :, with_reduction_mask]\n",
    "road_predictions = road_predictions.reshape(5, -1)\n",
    "actuals_reshaped = all_actuals.reshape(831, -1)\n",
    "road_actuals = actuals_reshaped[:, with_reduction_mask].reshape(-1)\n",
    "road_bias, road_variance = compute_bias_variance(road_actuals, road_predictions)\n",
    "results.append({\n",
    "    'Road Category': 'P/S/T Roads with capacity reduction',\n",
    "    'Bias': road_bias,\n",
    "    'Surrogate Model Variance': road_variance,\n",
    "    'Total Error': road_bias + road_variance\n",
    "})\n",
    "\n",
    "# Without capacity reduction\n",
    "without_reduction_mask = pst_mask & (gdf_with_og_values['capacity_reduction_rounded'] == 0)\n",
    "road_predictions = all_predictions[:, :, without_reduction_mask]\n",
    "road_predictions = road_predictions.reshape(5, -1)\n",
    "actuals_reshaped = all_actuals.reshape(831, -1)\n",
    "road_actuals = actuals_reshaped[:, without_reduction_mask].reshape(-1)\n",
    "road_bias, road_variance = compute_bias_variance(road_actuals, road_predictions)\n",
    "results.append({\n",
    "    'Road Category': 'P/S/T Roads without capacity reduction',\n",
    "    'Bias': road_bias,\n",
    "    'Surrogate Model Variance': road_variance,\n",
    "    'Total Error': road_bias + road_variance\n",
    "})\n",
    "\n",
    "# Convert to DataFrame for easier plotting\n",
    "df_results = pd.DataFrame(results)\n",
    "\n",
    "# Calculate Pearson correlation coefficient\n",
    "correlation, p_value = stats.pearsonr(df_results['Bias'], df_results['Surrogate Model Variance'])\n",
    "\n",
    "# plt.style.use('default')\n",
    "\n",
    "# Create scatter plot\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "plt.grid(False)\n",
    "ax = plt.gca()\n",
    "ax.set_axisbelow(False)\n",
    "ax.spines['top'].set_visible(True)\n",
    "ax.spines['right'].set_visible(True)\n",
    "\n",
    "# Plot points\n",
    "scatter = plt.scatter(df_results['Bias'], \n",
    "                     df_results['Surrogate Model Variance'],\n",
    "                     c=[plt.cm.Set2(i) for i in range(len(df_results))],\n",
    "                     s=100)\n",
    "\n",
    "# Add trend line\n",
    "z = np.polyfit(df_results['Bias'], df_results['Surrogate Model Variance'], 1)\n",
    "p = np.poly1d(z)\n",
    "x_trend = np.linspace(df_results['Bias'].min(), df_results['Bias'].max(), 100)\n",
    "plt.plot(x_trend, p(x_trend), \"gray\", linestyle=\"--\", alpha=0.7)\n",
    "\n",
    "# Add correlation coefficient to plot\n",
    "plt.text(0.05, 0.95, f'Pearson r = {correlation:.2f}', \n",
    "         transform=plt.gca().transAxes, \n",
    "         fontsize=12)\n",
    "\n",
    "# Add labels for each point\n",
    "for idx, row in df_results.iterrows():\n",
    "    plt.annotate(row['Road Category'], \n",
    "                (row['Bias'], row['Surrogate Model Variance']),\n",
    "                xytext=(5, 5), \n",
    "                textcoords='offset points',\n",
    "                fontsize=12)\n",
    "\n",
    "plt.xlabel('Bias', fontsize=12)\n",
    "plt.ylabel('Surrogate Model Variance', fontsize=12)\n",
    "# plt.title('Bias-Variance Trade-off by Road Category', fontsize=12)\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "\n",
    "# Set axes to start at 0\n",
    "plt.xlim(left=0)\n",
    "plt.ylim(bottom=0)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"bias_variance_tradeoff.png\", dpi = 500)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting Uncertainty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_predictions, all_actuals = get_ensemble_predictions_on_test_set(test_set_loader, device)\n",
    "\n",
    "# Standard deviation across ensemble members\n",
    "mean_uncertainties = np.std(all_predictions, axis=0)\n",
    "\n",
    "# Average uncertainties across all test samples\n",
    "mean_uncertainties = np.array(mean_uncertainties).mean(axis=0)\n",
    "\n",
    "# Create visualization\n",
    "flat_uc = np.sort(mean_uncertainties.flatten())\n",
    "percentile_25 = np.percentile(flat_uc, 25)\n",
    "percentile_75 = np.percentile(flat_uc, 75)\n",
    "\n",
    "print(f\"25th Percentile: {percentile_25:.4f}\")\n",
    "print(f\"75th Percentile: {percentile_75:.4f}\")\n",
    "print(f\"Mean uncertainty: {np.mean(flat_uc):.4f}\")\n",
    "print(f\"Max uncertainty: {np.max(flat_uc):.4f}\")\n",
    "\n",
    "# Add uncertainties to the GeoDataFrame\n",
    "gdf_with_og_values['ensemble_uncertainty'] = mean_uncertainties\n",
    "\n",
    "# Plot with discrete color levels\n",
    "discrete_thresholds = [percentile_25, percentile_75]\n",
    "\n",
    "pf.plot_combined_output(\n",
    "    gdf_input=gdf_with_og_values, \n",
    "    column_to_plot=\"ensemble_uncertainty\",\n",
    "    plot_contour_lines=False,\n",
    "    save_it=False, \n",
    "    number_to_plot=1,\n",
    "    zone_to_plot=\"this zone\",\n",
    "    is_predicted=True,\n",
    "    use_fixed_norm=False,\n",
    "    known_districts=False,\n",
    "    buffer=0.0005,\n",
    "    districts_of_interest=None,\n",
    "    scale_type='discrete',\n",
    "    discrete_thresholds=discrete_thresholds,\n",
    "    cmap='Reds'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ensemble_predictions(data, device):\n",
    "    \"\"\"Get raw predictions from all ensemble members\"\"\"\n",
    "    predictions = []\n",
    "    \n",
    "    for i, ensemble in enumerate(ensembles):\n",
    "        model_path = os.path.join(runs_path, ensemble, 'trained_model/model.pth')\n",
    "        model = load_ensemble(ensemble, model_path, use_dropout[i])\n",
    "        model.eval()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            pred = model(data.to(device))\n",
    "            pred = pred.cpu().numpy()\n",
    "            predictions.append(pred)\n",
    "\n",
    "            # # Use the existing mc_dropout_predict function with num_samples=1\n",
    "            # pred = mc_dropout_predict(model, data, num_samples=1, device=device)\n",
    "            # if isinstance(pred, tuple):\n",
    "            #     pred = pred[0]\n",
    "            # predictions.append(pred)\n",
    "    \n",
    "    return np.array(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's look at some example predictions and their relative uncertainties\n",
    "test_data = test_set_loader.dataset[0]\n",
    "ensemble_preds = get_ensemble_predictions(test_data, device)\n",
    "\n",
    "print(\"Shape of ensemble predictions:\", ensemble_preds.shape)\n",
    "print(\"\\nExample predictions for first 3 road segments:\")\n",
    "for i in range(3):\n",
    "    road_preds = ensemble_preds[:, i, 0]  # predictions from all ensembles for road i\n",
    "    mean_pred = np.mean(road_preds)\n",
    "    abs_uncertainty = np.std(road_preds)\n",
    "    rel_uncertainty = (abs_uncertainty / mean_pred) * 100  # as percentage\n",
    "    print(f\"\\nRoad {i}:\")\n",
    "    print(f\"Predictions from ensembles: {road_preds}\")\n",
    "    print(f\"Mean prediction: {mean_pred:.3f}\")\n",
    "    print(f\"Absolute uncertainty (std): {abs_uncertainty:.3f}\")\n",
    "    print(f\"Relative uncertainty (CV): {rel_uncertainty:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now compute relative uncertainties for all roads\n",
    "mean_relative_uncertainties = []\n",
    "\n",
    "print(\"\\nComputing relative uncertainties across test set...\")\n",
    "for i in tqdm(range(len(test_set_loader.dataset))):\n",
    "    test_data = test_set_loader.dataset[i]\n",
    "    ensemble_preds = get_ensemble_predictions(test_data, device)\n",
    "    \n",
    "    # Calculate relative uncertainty (CV) for each road\n",
    "    std_devs = np.std(ensemble_preds, axis=0)\n",
    "    means = np.mean(ensemble_preds, axis=0)\n",
    "    relative_uncertainties = (std_devs / means) * 100  # as percentage\n",
    "    mean_relative_uncertainties.append(relative_uncertainties)\n",
    "\n",
    "mean_relative_uncertainties = np.array(mean_relative_uncertainties).mean(axis=0)\n",
    "\n",
    "# Create visualization\n",
    "flat_uc = np.sort(mean_relative_uncertainties.flatten())\n",
    "percentile_25 = np.percentile(flat_uc, 25)\n",
    "percentile_75 = np.percentile(flat_uc, 75)\n",
    "\n",
    "print(\"\\nRelative Uncertainty Statistics:\")\n",
    "print(f\"25th Percentile: {percentile_25:.1f}%\")\n",
    "print(f\"75th Percentile: {percentile_75:.1f}%\")\n",
    "print(f\"Mean relative uncertainty: {np.mean(flat_uc):.1f}%\")\n",
    "print(f\"Max relative uncertainty: {np.max(flat_uc):.1f}%\")\n",
    "\n",
    "# Add relative uncertainties to the GeoDataFrame\n",
    "gdf_with_og_values['ensemble_uncertainty'] = mean_relative_uncertainties\n",
    "\n",
    "# Plot with discrete color levels\n",
    "discrete_thresholds = [percentile_25, percentile_75]\n",
    "\n",
    "pf.plot_combined_output(\n",
    "    gdf_input=gdf_with_og_values, \n",
    "    column_to_plot=\"ensemble_uncertainty\",\n",
    "    plot_contour_lines=False,\n",
    "    save_it=False, \n",
    "    number_to_plot=1,\n",
    "    zone_to_plot=\"this zone\",\n",
    "    is_predicted=True,\n",
    "    use_fixed_norm=False,\n",
    "    known_districts=False,\n",
    "    buffer=0.0005,\n",
    "    districts_of_interest=None,\n",
    "    scale_type='discrete',\n",
    "    discrete_thresholds=discrete_thresholds,\n",
    "    cmap='Reds'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now compute uncertainties using a more robust measure\n",
    "mean_uncertainties = []\n",
    "\n",
    "print(\"\\nComputing uncertainties across test set...\")\n",
    "for i in tqdm(range(len(test_set_loader.dataset))):\n",
    "    test_data = test_set_loader.dataset[i]\n",
    "    ensemble_preds = get_ensemble_predictions(test_data, device)\n",
    "    \n",
    "    # Calculate uncertainty as the range of predictions\n",
    "    # (max - min) / (|mean| + epsilon) to handle zeros and negative values\n",
    "    max_preds = np.max(ensemble_preds, axis=0)\n",
    "    min_preds = np.min(ensemble_preds, axis=0)\n",
    "    mean_preds = np.mean(ensemble_preds, axis=0)\n",
    "    epsilon = 1.0  # small constant to avoid division by zero and handle small values\n",
    "    \n",
    "    uncertainty = (max_preds - min_preds) / (np.abs(mean_preds) + epsilon)\n",
    "    mean_uncertainties.append(uncertainty)\n",
    "\n",
    "mean_uncertainties = np.array(mean_uncertainties).mean(axis=0)\n",
    "\n",
    "# Print some statistics\n",
    "print(\"\\nUncertainty Statistics:\")\n",
    "print(f\"Mean uncertainty: {np.mean(mean_uncertainties):.3f}\")\n",
    "print(f\"Max uncertainty: {np.max(mean_uncertainties):.3f}\")\n",
    "print(f\"Min uncertainty: {np.min(mean_uncertainties):.3f}\")\n",
    "\n",
    "# Add uncertainties to the GeoDataFrame\n",
    "gdf_with_og_values['ensemble_uncertainty'] = mean_uncertainties\n",
    "\n",
    "# Plot with discrete color levels\n",
    "percentile_25 = np.percentile(mean_uncertainties, 25)\n",
    "percentile_75 = np.percentile(mean_uncertainties, 75)\n",
    "discrete_thresholds = [percentile_25, percentile_75]\n",
    "\n",
    "pf.plot_combined_output(\n",
    "    gdf_input=gdf_with_og_values, \n",
    "    column_to_plot=\"ensemble_uncertainty\",\n",
    "    plot_contour_lines=False,\n",
    "    save_it=False, \n",
    "    number_to_plot=1,\n",
    "    zone_to_plot=\"this zone\",\n",
    "    is_predicted=True,\n",
    "    use_fixed_norm=False,\n",
    "    known_districts=False,\n",
    "    buffer=0.0005,\n",
    "    districts_of_interest=None,\n",
    "    scale_type='discrete',\n",
    "    discrete_thresholds=discrete_thresholds,\n",
    "    cmap='Reds'\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chenhao-gnn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
