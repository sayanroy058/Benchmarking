{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- ABSTRACT -->\n",
    "\n",
    "With this script, we apply monte carlo dropout to the trained model and check how well it performs. The result is a plot of the uncertainty of the model's predictions. However, it seems that the uncertainty is not very high."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import joblib\n",
    "\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import geopandas as gpd\n",
    "\n",
    "import torch\n",
    "\n",
    "# Add the 'scripts' directory to Python Path\n",
    "scripts_path=os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "if scripts_path not in sys.path:\n",
    "    sys.path.append(scripts_path)\n",
    "\n",
    "import evaluation.help_functions as hf\n",
    "import evaluation.plot_functions as pf\n",
    "\n",
    "from gnn.help_functions import mc_dropout_predict\n",
    "from gnn.models.point_net_transf_gat import PointNetTransfGAT\n",
    "from data_preprocessing.help_functions import highway_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the absolute path to the project root\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), '..', '..'))\n",
    "\n",
    "# Paths\n",
    "run_path = os.path.join(project_root, \"data\", \"runs_01_2025\", \"wannabe_best_6\")\n",
    "districts = gpd.read_file(os.path.join(project_root, \"data\", \"visualisation\", \"districts_paris.geojson\"))\n",
    "base_case_path = os.path.join(project_root, \"data\", \"links_and_stats\", \"pop_1pct_basecase_average_output_links.geojson\")\n",
    "result_path = 'results/'\n",
    "\n",
    "\n",
    "# GNN Parameters\n",
    "point_net_conv_layer_structure_local_mlp=\"256\"\n",
    "point_net_conv_layer_structure_global_mlp = \"512\"\n",
    "gat_conv_layer_structure = \"128,256,512\"\n",
    "dropout = 0.3\n",
    "use_dropout = False\n",
    "predict_mode_stats = False\n",
    "in_channels = 5\n",
    "out_channels = 1\n",
    "\n",
    "links_base_case = gpd.read_file(base_case_path, crs=\"EPSG:4326\")\n",
    "data_created_during_training = os.path.join(run_path, 'data_created_during_training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################################\n",
    "### Load test data from the run itself! ###\n",
    "###########################################\n",
    "\n",
    "# Load scalers\n",
    "scaler_x = joblib.load(os.path.join(data_created_during_training, 'test_x_scaler.pkl'))\n",
    "scaler_pos = joblib.load(os.path.join(data_created_during_training, 'test_pos_scaler.pkl'))\n",
    "\n",
    "# Load the test dataset created during training\n",
    "test_set_dl = torch.load(os.path.join(data_created_during_training, 'test_dl.pt'))\n",
    "\n",
    "# Load the DataLoader parameters\n",
    "with open(os.path.join(data_created_during_training, 'test_loader_params.json'), 'r') as f:\n",
    "    test_set_dl_loader_params = json.load(f)\n",
    "    \n",
    "# Remove or correct collate_fn if it is incorrectly specified\n",
    "if 'collate_fn' in test_set_dl_loader_params and isinstance(test_set_dl_loader_params['collate_fn'], str):\n",
    "    del test_set_dl_loader_params['collate_fn']  # Remove it to use the default collate function\n",
    "    \n",
    "test_set_loader = torch.utils.data.DataLoader(test_set_dl, **test_set_dl_loader_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "point_net_conv_layer_structure_local_mlp = [int(x) for x in point_net_conv_layer_structure_local_mlp.split(',')]\n",
    "point_net_conv_layer_structure_global_mlp = [int(x) for x in point_net_conv_layer_structure_global_mlp.split(',')]\n",
    "gat_conv_layer_structure = [int(x) for x in gat_conv_layer_structure.split(',')]\n",
    "\n",
    "model = PointNetTransfGAT(in_channels=in_channels, out_channels=out_channels,\n",
    "              point_net_conv_layer_structure_local_mlp=point_net_conv_layer_structure_local_mlp, \n",
    "              point_net_conv_layer_structure_global_mlp = point_net_conv_layer_structure_global_mlp,\n",
    "              gat_conv_layer_structure=gat_conv_layer_structure,\n",
    "              dropout=dropout,\n",
    "              use_dropout=use_dropout,\n",
    "              predict_mode_stats=predict_mode_stats)\n",
    "\n",
    "# Load the model state dictionary\n",
    "model_path = os.path.join(run_path, 'trained_model/model.pth')\n",
    "model.load_state_dict(torch.load(model_path), strict=False)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "\n",
    "loss_fct = torch.nn.MSELoss().to(dtype=torch.float32).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, r_squared, actual_vals, predictions, baseline_loss = hf.validate_model_on_test_set(model, test_set_loader.dataset, loss_fct, device)\n",
    "\n",
    "print(f\"Test Loss: {test_loss}\")\n",
    "print(f\"R-squared: {r_squared}\")\n",
    "print(f\"Baseline Loss: {baseline_loss}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next, we will look at single elements of the test set and visualize the performance of the model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 2 # index from the test set, pick a particular sample\n",
    "\n",
    "fixed_norm_max = 50\n",
    "    \n",
    "my_test_data = test_set_loader.dataset[i]\n",
    "my_test_x = test_set_loader.dataset[i].x\n",
    "my_test_x = my_test_x.to('cpu')\n",
    "\n",
    "test_loss_my_test_data, r_squared_my_test_data, actual_vals_my_test_data, predictions_my_test_data, baseline_loss_my_test_data = hf.validate_model_on_test_set(model, my_test_data, loss_fct, device)\n",
    "print(f\"Sample {i}\")\n",
    "print(f\"Test Loss: {test_loss_my_test_data}\")\n",
    "print(f\"R-squared: {r_squared_my_test_data}\")\n",
    "print(f\"Baseline Loss: {baseline_loss_my_test_data}\")\n",
    "\n",
    "inversed_x = scaler_x.inverse_transform(my_test_x)\n",
    "\n",
    "gdf_with_og_values = hf.data_to_geodataframe_with_og_values(data=my_test_data, original_gdf=links_base_case, predicted_values=predictions_my_test_data, inversed_x=inversed_x)\n",
    "gdf_with_og_values['capacity_reduction_rounded'] = gdf_with_og_values['capacity_reduction'].round(decimals=3)\n",
    "gdf_with_og_values['highway'] = gdf_with_og_values['highway'].map(highway_mapping)\n",
    "\n",
    "# gdf_with_og_values['district'] = gdf_with_og_values.apply(lambda row: districts[districts.contains(row.geometry)].iloc[0]['c_ar'] if not districts[districts.contains(row.geometry)].empty else 'Unknown', axis=1)\n",
    "# gdf_with_og_values = gpd.sjoin(gdf_with_og_values, districts, how='left', op='intersects')\n",
    "\n",
    "print(f\"\\nPredicted:\")\n",
    "pf.plot_combined_output(gdf_input=gdf_with_og_values, column_to_plot=\"vol_car_change_predicted\", \n",
    "                        save_it=False, number_to_plot=i, zone_to_plot=\"this zone\", is_predicted=True, alpha=0, use_fixed_norm=True, \n",
    "                        fixed_norm_max=fixed_norm_max, known_districts=False, buffer=0.0005, districts_of_interest=None,\n",
    "                        plot_contour_lines=True, plot_policy_roads=False, result_path=result_path, with_legend=False)\n",
    "\n",
    "print(f\"Actual:\")\n",
    "pf.plot_combined_output(gdf_input=gdf_with_og_values, column_to_plot=\"vol_car_change_actual\", save_it=False, \n",
    "                        number_to_plot=i, zone_to_plot=\"this zone\", is_predicted=False,alpha=10,use_fixed_norm=True, \n",
    "                        fixed_norm_max=fixed_norm_max, known_districts=False, buffer=0.0005, districts_of_interest=None,\n",
    "                        plot_contour_lines=True, plot_policy_roads=False, result_path=result_path, with_legend=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MC DROPOUT on Single Sample\n",
    "\n",
    "i = 32\n",
    "test_data = test_set_loader.dataset[i]\n",
    "test_x = test_set_loader.dataset[i].x\n",
    "test_x = test_x.to('cpu')\n",
    "\n",
    "test_loss, r_squared, actual_vals, predictions, baseline_loss = hf.validate_model_on_test_set(model, test_data, loss_fct, device)\n",
    "print(f\"Test {i}\")\n",
    "print(f\"Test Loss: {test_loss}\")\n",
    "print(f\"R-squared: {r_squared}\")\n",
    "print(f\"Baseline Loss: {baseline_loss}\")\n",
    "\n",
    "inversed_x = scaler_x.inverse_transform(test_x)\n",
    "mean_predictions, uncertainties = mc_dropout_predict(model, test_data, num_samples=50, device=device)\n",
    "\n",
    "gdf_with_og_values = hf.data_to_geodataframe_with_og_values(data=test_data, original_gdf=links_base_case, predicted_values=predictions, inversed_x=inversed_x, use_all_features=False)\n",
    "gdf_with_og_values['capacity_reduction_rounded'] = gdf_with_og_values['capacity_reduction'].round(decimals=3)\n",
    "gdf_with_og_values['highway'] = gdf_with_og_values['highway'].map(highway_mapping)\n",
    "gdf_with_og_values['mc_uncertainty'] = uncertainties\n",
    "\n",
    "pf.plot_combined_output(gdf_input=gdf_with_og_values, column_to_plot=\"mc_uncertainty\", plot_contour_lines=False,\n",
    "                        save_it=False, number_to_plot=i, zone_to_plot=\"this zone\", is_predicted=True, use_fixed_norm=False,\n",
    "                        known_districts=False, buffer=0.0005, districts_of_interest=None, cmap='Reds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MC DROPOUT on entire test set\n",
    "\n",
    "mean_uncertainties = []\n",
    "\n",
    "for i in tqdm(range(len(test_set_loader.dataset))):\n",
    "    \n",
    "    test_data = test_set_loader.dataset[i]\n",
    "    test_x = test_set_loader.dataset[i].x\n",
    "    test_x = test_x.to('cpu')\n",
    "\n",
    "    mean_predictions, uncertainties = mc_dropout_predict(model, test_data, num_samples=50, device=device)\n",
    "    mean_uncertainties.append(uncertainties)\n",
    "\n",
    "mean_uncertainties = np.array(mean_uncertainties).mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On the last sample, but does not matter\n",
    "inversed_x = scaler_x.inverse_transform(test_x)\n",
    "gdf_with_og_values = hf.data_to_geodataframe_with_og_values(data=test_data, original_gdf=links_base_case, predicted_values=mean_predictions, inversed_x=inversed_x, use_all_features=False)\n",
    "gdf_with_og_values['capacity_reduction_rounded'] = gdf_with_og_values['capacity_reduction'].round(decimals=3)\n",
    "gdf_with_og_values['highway'] = gdf_with_og_values['highway'].map(highway_mapping)\n",
    "gdf_with_og_values['mc_uncertainty'] = mean_uncertainties\n",
    "\n",
    "pf.plot_combined_output(gdf_input=gdf_with_og_values, column_to_plot=\"mc_uncertainty\", plot_contour_lines=False,\n",
    "                        save_it=False, number_to_plot=i+1, zone_to_plot=\"this zone\", is_predicted=True, use_fixed_norm=False,\n",
    "                        known_districts=False, buffer=0.0005, districts_of_interest=None, cmap='Reds')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chenhao-gnn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
